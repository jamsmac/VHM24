# ============================================================================
# Prometheus Alert Rules for VendHub Manager
# ============================================================================

groups:
  # ==========================================================================
  # Backend API Alerts
  # ==========================================================================
  - name: backend_api_alerts
    interval: 30s
    rules:
      - alert: BackendAPIDown
        expr: up{job="vendhub-backend"} == 0
        for: 2m
        labels:
          severity: critical
          component: api
        annotations:
          summary: "Backend API is down"
          description: "Backend API has been down for more than 2 minutes"

      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
          component: api
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} over the last 5 minutes"

      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
          component: api
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ $value }}s"

      - alert: HighMemoryUsage
        expr: process_resident_memory_bytes / 1024 / 1024 > 1500
        for: 10m
        labels:
          severity: warning
          component: api
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ $value | humanize }}MB"

  # ==========================================================================
  # Worker Alerts
  # ==========================================================================
  - name: worker_alerts
    interval: 30s
    rules:
      - alert: WorkerDown
        expr: up{component="worker"} == 0
        for: 2m
        labels:
          severity: critical
          component: worker
        annotations:
          summary: "Worker {{ $labels.job }} is down"
          description: "Worker has been down for more than 2 minutes"

      - alert: HighJobFailureRate
        expr: rate(bullmq_job_failed_total[10m]) > 0.1
        for: 10m
        labels:
          severity: warning
          component: worker
        annotations:
          summary: "High job failure rate"
          description: "Job failure rate is {{ $value | humanizePercentage }}"

      - alert: QueueBacklog
        expr: bullmq_queue_waiting > 1000
        for: 15m
        labels:
          severity: warning
          component: worker
        annotations:
          summary: "High queue backlog"
          description: "Queue has {{ $value }} waiting jobs"

  # ==========================================================================
  # Database Alerts
  # ==========================================================================
  - name: database_alerts
    interval: 30s
    rules:
      - alert: PostgreSQLDown
        expr: up{job="postgres"} == 0
        for: 1m
        labels:
          severity: critical
          component: database
        annotations:
          summary: "PostgreSQL is down"
          description: "PostgreSQL database has been down for more than 1 minute"

      - alert: HighDatabaseConnections
        expr: pg_stat_database_numbackends > 80
        for: 5m
        labels:
          severity: warning
          component: database
        annotations:
          summary: "High number of database connections"
          description: "Database has {{ $value }} active connections"

      - alert: DatabaseDiskSpaceLow
        expr: pg_database_size_bytes / (1024*1024*1024) > 50
        for: 10m
        labels:
          severity: warning
          component: database
        annotations:
          summary: "Database disk space running low"
          description: "Database size is {{ $value | humanize }}GB"

  # ==========================================================================
  # Redis Alerts
  # ==========================================================================
  - name: redis_alerts
    interval: 30s
    rules:
      - alert: RedisDown
        expr: up{job="redis"} == 0
        for: 1m
        labels:
          severity: critical
          component: cache
        annotations:
          summary: "Redis is down"
          description: "Redis has been down for more than 1 minute"

      - alert: RedisHighMemoryUsage
        expr: redis_memory_used_bytes / redis_memory_max_bytes > 0.9
        for: 5m
        labels:
          severity: warning
          component: cache
        annotations:
          summary: "Redis memory usage is high"
          description: "Redis memory usage is {{ $value | humanizePercentage }}"

  # ==========================================================================
  # Storage Alerts
  # ==========================================================================
  - name: storage_alerts
    interval: 30s
    rules:
      - alert: MinIODown
        expr: up{job="minio"} == 0
        for: 2m
        labels:
          severity: critical
          component: storage
        annotations:
          summary: "MinIO is down"
          description: "MinIO storage has been down for more than 2 minutes"

  # ==========================================================================
  # Security Alerts
  # ==========================================================================
  - name: security_alerts
    interval: 30s
    rules:
      - alert: HighLoginFailureRate
        expr: rate(vendhub_login_failures_total[5m]) > 0.5
        for: 5m
        labels:
          severity: warning
          component: security
        annotations:
          summary: "High login failure rate detected"
          description: "Login failure rate is {{ $value | humanizePercentage }} - possible brute force attack"

      - alert: RateLimitExceeded
        expr: increase(vendhub_http_request_errors_total{status="429"}[5m]) > 100
        for: 5m
        labels:
          severity: warning
          component: security
        annotations:
          summary: "High rate limiting activity"
          description: "{{ $value }} requests rate limited in last 5 minutes - possible attack"

      - alert: SuspiciousLoginPattern
        expr: increase(vendhub_login_failures_total{reason="invalid_credentials"}[1h]) > 50
        for: 10m
        labels:
          severity: critical
          component: security
        annotations:
          summary: "Suspicious login pattern detected"
          description: "{{ $value }} failed logins in the last hour - possible credential stuffing attack"

      - alert: SessionAnomalies
        expr: rate(vendhub_sessions_created_total[5m]) > 10
        for: 5m
        labels:
          severity: warning
          component: security
        annotations:
          summary: "Unusual session creation rate"
          description: "Session creation rate is {{ $value }}/s - investigate for potential abuse"

      - alert: TokenRefreshAnomalies
        expr: rate(vendhub_http_requests_total{route="/api/auth/refresh", status="401"}[5m]) > 1
        for: 5m
        labels:
          severity: warning
          component: security
        annotations:
          summary: "High token refresh failures"
          description: "Token refresh failure rate is {{ $value }}/s - possible token theft"

  # ==========================================================================
  # Business Alerts
  # ==========================================================================
  - name: business_alerts
    interval: 60s
    rules:
      - alert: LowTaskCompletionRate
        expr: sum(increase(vendhub_tasks_completed_total{status="completed"}[24h])) / sum(increase(vendhub_tasks_created_total[24h])) < 0.7
        for: 1h
        labels:
          severity: warning
          component: business
        annotations:
          summary: "Low task completion rate"
          description: "Task completion rate is {{ $value | humanizePercentage }} - below 70% threshold"

      - alert: HighMachineOfflineRate
        expr: vendhub_machines_offline{reason="total"} / (vendhub_machines_active{status="active"} + vendhub_machines_offline{reason="total"}) > 0.1
        for: 30m
        labels:
          severity: warning
          component: business
        annotations:
          summary: "High machine offline rate"
          description: "{{ $value | humanizePercentage }} of machines are offline"

      - alert: UrgentTasksNotCompleted
        expr: increase(vendhub_tasks_created_total{priority="urgent"}[4h]) - increase(vendhub_tasks_completed_total{priority="urgent", status="completed"}[4h]) > 5
        for: 1h
        labels:
          severity: critical
          component: business
        annotations:
          summary: "Urgent tasks pending"
          description: "{{ $value }} urgent tasks have not been completed in 4 hours"

      - alert: InventoryMovementAnomaly
        expr: rate(vendhub_inventory_movements_total[1h]) == 0
        for: 4h
        labels:
          severity: warning
          component: business
        annotations:
          summary: "No inventory movements"
          description: "No inventory movements recorded in the last 4 hours during business hours"

      - alert: TaskProcessingDelayed
        expr: histogram_quantile(0.95, rate(vendhub_task_duration_seconds_bucket[1h])) > 7200
        for: 1h
        labels:
          severity: warning
          component: business
        annotations:
          summary: "Task processing delayed"
          description: "95th percentile task duration is {{ $value | humanizeDuration }} - above 2 hour threshold"
