import { Injectable, Logger } from '@nestjs/common';
import OpenAI from 'openai';
import * as fs from 'fs';
import * as path from 'path';
import { promisify } from 'util';

const writeFileAsync = promisify(fs.writeFile);
const unlinkAsync = promisify(fs.unlink);

/**
 * Parsed command from voice message
 */
export interface VoiceCommand {
  intent: 'tasks' | 'machines' | 'stats' | 'help' | 'start_task' | 'complete_task' | 'unknown';
  confidence: number;
  parameters?: {
    taskId?: string;
    machineNumber?: string;
    taskNumber?: string;
    [key: string]: string | undefined;
  };
  originalText: string;
}

/**
 * Service for handling voice messages in Telegram bot
 *
 * Uses OpenAI Whisper API for speech-to-text transcription
 * Supports Russian, English, and Uzbek languages
 */
@Injectable()
export class TelegramVoiceService {
  private readonly logger = new Logger(TelegramVoiceService.name);
  private openai: OpenAI | null = null;
  // Use /tmp directory which has proper permissions in containerized environments
  private readonly tempDir =
    process.env.NODE_ENV === 'production'
      ? '/tmp/voice'
      : path.join(process.cwd(), 'temp', 'voice');
  private tempDirAvailable = false;

  constructor() {
    this.initializeOpenAI();
    this.ensureTempDir();
  }

  /**
   * Initialize OpenAI client
   */
  private initializeOpenAI(): void {
    const apiKey = process.env.OPENAI_API_KEY;

    if (!apiKey) {
      this.logger.warn(
        'OPENAI_API_KEY not configured. Voice transcription will be disabled. ' +
          'Add OPENAI_API_KEY to .env to enable voice support.',
      );
      return;
    }

    try {
      this.openai = new OpenAI({
        apiKey,
      });
      this.logger.log('OpenAI Whisper API initialized for voice transcription');
    } catch (error) {
      this.logger.error('Failed to initialize OpenAI client', error);
    }
  }

  /**
   * Ensure temp directory exists for voice file storage
   */
  private ensureTempDir(): void {
    try {
      if (!fs.existsSync(this.tempDir)) {
        fs.mkdirSync(this.tempDir, { recursive: true });
        this.logger.log(`Created temp directory for voice files: ${this.tempDir}`);
      }
      this.tempDirAvailable = true;
    } catch (error) {
      this.logger.warn(
        `Failed to create temp directory for voice files: ${this.tempDir}. ` +
          `Voice transcription will be disabled. Error: ${error.message}`,
      );
      this.tempDirAvailable = false;
    }
  }

  /**
   * Check if voice transcription is available
   */
  isAvailable(): boolean {
    return this.openai !== null && this.tempDirAvailable;
  }

  /**
   * Transcribe voice message to text using OpenAI Whisper
   *
   * @param audioBuffer - Voice message audio data (OGG format from Telegram)
   * @param language - Language code (ru, en, uz)
   * @returns Transcribed text
   */
  async transcribeVoice(audioBuffer: Buffer, language: string = 'ru'): Promise<string> {
    if (!this.openai) {
      throw new Error('Voice transcription not available. OPENAI_API_KEY not configured.');
    }

    if (!this.tempDirAvailable) {
      throw new Error('Voice transcription not available. Temporary directory not accessible.');
    }

    let tempFilePath: string | null = null;

    try {
      // Save buffer to temporary file (Whisper API requires a file)
      tempFilePath = path.join(this.tempDir, `voice_${Date.now()}.ogg`);
      await writeFileAsync(tempFilePath, audioBuffer);

      this.logger.debug(`Transcribing voice file: ${tempFilePath} (language: ${language})`);

      // Call Whisper API
      const transcription = await this.openai.audio.transcriptions.create({
        file: fs.createReadStream(tempFilePath),
        model: 'whisper-1',
        language: language === 'uz' ? 'ru' : language, // Whisper doesn't have Uzbek, use Russian
        response_format: 'text',
      });

      const text = transcription.toString().trim();

      this.logger.log(`Voice transcribed successfully: "${text.substring(0, 50)}..."`);

      return text;
    } catch (error) {
      this.logger.error('Failed to transcribe voice message', error);
      throw new Error('–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ');
    } finally {
      // Clean up temporary file
      if (tempFilePath && fs.existsSync(tempFilePath)) {
        try {
          await unlinkAsync(tempFilePath);
        } catch (err) {
          this.logger.warn(`Failed to delete temp file: ${tempFilePath}`, err);
        }
      }
    }
  }

  /**
   * Parse command intent from transcribed text using NLP
   *
   * Supports natural language commands in Russian:
   * - "–ø–æ–∫–∞–∂–∏ –º–æ–∏ –∑–∞–¥–∞—á–∏" -> tasks
   * - "–ø–æ–∫–∞–∂–∏ –∞–ø–ø–∞—Ä–∞—Ç—ã" -> machines
   * - "—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞" -> stats
   * - "–Ω–∞—á–∞—Ç—å –∑–∞–¥–∞—á—É –Ω–æ–º–µ—Ä 3" -> start_task
   * - "–∑–∞–≤–µ—Ä—à–∏—Ç—å –∑–∞–¥–∞—á—É" -> complete_task
   *
   * @param text - Transcribed text from voice
   * @returns Parsed command with intent and parameters
   */
  parseCommand(text: string): VoiceCommand {
    const lowerText = text.toLowerCase().trim();

    // Task list commands
    if (this.matchesKeywords(lowerText, ['–∑–∞–¥–∞—á', 'task', '—Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á', '–º–æ–∏ –∑–∞–¥–∞—á–∏'])) {
      return {
        intent: 'tasks',
        confidence: 0.9,
        originalText: text,
      };
    }

    // Machine list commands
    if (
      this.matchesKeywords(lowerText, ['–∞–ø–ø–∞—Ä–∞—Ç', 'machine', '–ø–æ–∫–∞–∂–∏ –∞–ø–ø–∞—Ä–∞—Ç—ã', '—Å–ø–∏—Å–æ–∫ –∞–ø–ø–∞—Ä–∞—Ç–æ–≤'])
    ) {
      return {
        intent: 'machines',
        confidence: 0.9,
        originalText: text,
      };
    }

    // Statistics commands
    if (this.matchesKeywords(lowerText, ['—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫', '—Å—Ç–∞—Ç—Å', 'stats', '–ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏'])) {
      return {
        intent: 'stats',
        confidence: 0.9,
        originalText: text,
      };
    }

    // Help commands
    if (this.matchesKeywords(lowerText, ['–ø–æ–º–æ—â', '—Å–ø—Ä–∞–≤–∫', 'help', '—á—Ç–æ —Ç—ã —É–º–µ–µ—à—å'])) {
      return {
        intent: 'help',
        confidence: 0.95,
        originalText: text,
      };
    }

    // Start task commands
    if (this.matchesKeywords(lowerText, ['–Ω–∞—á–∞—Ç—å', 'start', '–∑–∞–ø—É—Å—Ç–∏—Ç—å –∑–∞–¥–∞—á—É', '–ø—Ä–∏—Å—Ç—É–ø–∏—Ç—å'])) {
      // Try to extract task number or ID
      const taskNumberMatch = lowerText.match(/–Ω–æ–º–µ—Ä\s*(\d+)|–∑–∞–¥–∞—á[—É–∞]\s*(\d+)|task\s*(\d+)/);
      const taskNumber = taskNumberMatch
        ? taskNumberMatch[1] || taskNumberMatch[2] || taskNumberMatch[3]
        : undefined;

      return {
        intent: 'start_task',
        confidence: 0.85,
        parameters: taskNumber ? { taskNumber } : undefined,
        originalText: text,
      };
    }

    // Complete task commands
    if (this.matchesKeywords(lowerText, ['–∑–∞–≤–µ—Ä—à–∏—Ç—å', 'complete', '–∑–∞–∫–æ–Ω—á–∏—Ç—å –∑–∞–¥–∞—á—É', 'finish'])) {
      return {
        intent: 'complete_task',
        confidence: 0.85,
        originalText: text,
      };
    }

    // Unknown command
    return {
      intent: 'unknown',
      confidence: 0.0,
      originalText: text,
    };
  }

  /**
   * Check if text matches any of the keywords (with partial matching)
   */
  private matchesKeywords(text: string, keywords: string[]): boolean {
    return keywords.some((keyword) => text.includes(keyword));
  }

  /**
   * Generate user-friendly response for voice command
   *
   * @param command - Parsed voice command
   * @param language - User's language preference
   * @returns Response message
   */
  getVoiceCommandResponse(command: VoiceCommand, language: 'ru' | 'en' = 'ru'): string {
    if (language === 'ru') {
      switch (command.intent) {
        case 'tasks':
          return '‚úÖ –ü–æ–∫–∞–∑—ã–≤–∞—é –≤–∞—à–∏ –∑–∞–¥–∞—á–∏...';
        case 'machines':
          return '‚úÖ –ü–æ–∫–∞–∑—ã–≤–∞—é —Å–ø–∏—Å–æ–∫ –∞–ø–ø–∞—Ä–∞—Ç–æ–≤...';
        case 'stats':
          return '‚úÖ –ó–∞–≥—Ä—É–∂–∞—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É...';
        case 'help':
          return '‚úÖ –ü–æ–∫–∞–∑—ã–≤–∞—é —Å–ø—Ä–∞–≤–∫—É...';
        case 'start_task':
          if (command.parameters?.taskNumber) {
            return `‚úÖ –ù–∞—á–∏–Ω–∞—é –∑–∞–¥–∞—á—É –Ω–æ–º–µ—Ä ${command.parameters.taskNumber}...`;
          }
          return '‚úÖ –ü–æ–∫–∞–∑—ã–≤–∞—é –≤–∞—à–∏ –∑–∞–¥–∞—á–∏. –í—ã–±–µ—Ä–∏—Ç–µ –∑–∞–¥–∞—á—É –¥–ª—è –Ω–∞—á–∞–ª–∞...';
        case 'complete_task':
          return '‚úÖ –î–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫—É "–ó–∞–≤–µ—Ä—à–∏—Ç—å" –≤ —Å–ø–∏—Å–∫–µ –∑–∞–¥–∞—á';
        default:
          return (
            'ü§î –ù–µ –ø–æ–Ω—è–ª –∫–æ–º–∞–Ω–¥—É. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ:\n\n' +
            '‚Ä¢ "–ü–æ–∫–∞–∂–∏ –º–æ–∏ –∑–∞–¥–∞—á–∏"\n' +
            '‚Ä¢ "–ü–æ–∫–∞–∂–∏ –∞–ø–ø–∞—Ä–∞—Ç—ã"\n' +
            '‚Ä¢ "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"\n' +
            '‚Ä¢ "–ü–æ–º–æ—â—å"'
          );
      }
    } else {
      switch (command.intent) {
        case 'tasks':
          return '‚úÖ Showing your tasks...';
        case 'machines':
          return '‚úÖ Showing machines...';
        case 'stats':
          return '‚úÖ Loading statistics...';
        case 'help':
          return '‚úÖ Showing help...';
        case 'start_task':
          if (command.parameters?.taskNumber) {
            return `‚úÖ Starting task #${command.parameters.taskNumber}...`;
          }
          return '‚úÖ Showing your tasks. Choose a task to start...';
        case 'complete_task':
          return '‚úÖ To complete a task, use the "Complete" button in task list';
        default:
          return (
            'ü§î Command not recognized. Try:\n\n' +
            '‚Ä¢ "Show my tasks"\n' +
            '‚Ä¢ "Show machines"\n' +
            '‚Ä¢ "Statistics"\n' +
            '‚Ä¢ "Help"'
          );
      }
    }
  }

  /**
   * Clean up old voice files (should be called periodically)
   */
  async cleanupOldFiles(maxAgeHours: number = 24): Promise<void> {
    try {
      if (!fs.existsSync(this.tempDir)) {
        return;
      }

      const files = fs.readdirSync(this.tempDir);
      const now = Date.now();
      const maxAgeMs = maxAgeHours * 60 * 60 * 1000;

      let deletedCount = 0;

      for (const file of files) {
        const filePath = path.join(this.tempDir, file);
        const stats = fs.statSync(filePath);

        if (now - stats.mtimeMs > maxAgeMs) {
          await unlinkAsync(filePath);
          deletedCount++;
        }
      }

      if (deletedCount > 0) {
        this.logger.log(`Cleaned up ${deletedCount} old voice files`);
      }
    } catch (error) {
      this.logger.error('Error cleaning up voice files', error);
    }
  }
}
